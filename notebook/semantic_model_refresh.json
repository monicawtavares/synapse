{
	"name": "semantic_model_refresh",
	"properties": {
		"folder": {
			"name": "DataPlatform/sources"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "709502d8-438e-4b74-9503-dc6c245c0b2b"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import requests\r\n",
					"import datetime\r\n",
					"import json"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run neudesic-odp/framework/neuacc-odp-framework"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"dataset_name = \"\" "
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\r\n",
					"# Getting information for Tenant ID, Client ID (Service Principal) and Client Password\r\n",
					"tenant_id = mssparkutils.credentials.getSecret(f\"chem{get_current_env()}euskv01\", 'FabricSPTenantID',\"AzureKeyVault\")\r\n",
					"client_id = mssparkutils.credentials.getSecret(f\"chem{get_current_env()}euskv01\", 'FabricSPAppId','AzureKeyVault')\r\n",
					"client_secret = mssparkutils.credentials.getSecret(f\"chem{get_current_env()}euskv01\", \"FabricSPClientSecret\", \"AzureKeyVault\")\r\n",
					"workspace_display_name = get_fabric_workspace()"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import requests\r\n",
					"import datetime\r\n",
					"import time\r\n",
					"import json  # Ensure you import the `json` module for serialization\r\n",
					"\r\n",
					"# Power BI API endpoint\r\n",
					"power_bi_api_url = \"https://api.powerbi.com/v1.0/myorg\"\r\n",
					"\r\n",
					"def get_access_token_with_legacy_flow(tenant_id, client_id, client_secret):\r\n",
					"    \"\"\"\r\n",
					"    Authenticate to Azure AD and retrieve an access token for Power BI REST API.\r\n",
					"\r\n",
					"    Args:\r\n",
					"        tenant_id (str): Azure AD tenant ID.\r\n",
					"        client_id (str): Client ID of the service principal.\r\n",
					"        client_secret (str): Client secret of the service principal.\r\n",
					"\r\n",
					"    Returns:\r\n",
					"        tuple: A tuple containing the access token (str) and expiration time (datetime).\r\n",
					"    \"\"\"\r\n",
					"    try:\r\n",
					"        token_endpoint = f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\r\n",
					"        resource_endpoint = \"https://analysis.windows.net/powerbi/api\"\r\n",
					"\r\n",
					"        token_payload = {\r\n",
					"            \"grant_type\": \"client_credentials\",\r\n",
					"            \"client_id\": client_id,\r\n",
					"            \"client_secret\": client_secret,\r\n",
					"            \"resource\": resource_endpoint,\r\n",
					"        }\r\n",
					"\r\n",
					"        response = requests.post(token_endpoint, data=token_payload)\r\n",
					"\r\n",
					"        if response.status_code == 200:\r\n",
					"            token_data = response.json()\r\n",
					"            token = token_data.get(\"access_token\")\r\n",
					"            access_token = f\"Bearer {token}\"\r\n",
					"            expires_on = token_data.get(\"expires_on\")\r\n",
					"            token_expiration = datetime.datetime.utcfromtimestamp(int(expires_on)) if expires_on else None\r\n",
					"            print(\"Access token generated successfully.\")\r\n",
					"            return access_token, token_expiration\r\n",
					"        else:\r\n",
					"            raise requests.HTTPError(f\"Token generation failed: {response.text}\")\r\n",
					"    except Exception as e:\r\n",
					"        print(f\"Error generating access token: {e}\")\r\n",
					"        raise\r\n",
					"\r\n",
					"# Function to refresh token automatically\r\n",
					"def get_valid_token(token_details, tenant_id, client_id, client_secret):\r\n",
					"    \"\"\"\r\n",
					"    Check token validity and refresh it if expired or close to expiry.\r\n",
					"    \"\"\"\r\n",
					"    access_token, expiration_time = token_details\r\n",
					"\r\n",
					"    # Renew token if it expires in less than 5 minutes\r\n",
					"    if expiration_time and (expiration_time - datetime.datetime.utcnow()).total_seconds() < 300:\r\n",
					"        print(\"Token is close to expiration. Generating a new token...\")\r\n",
					"        return get_access_token_with_legacy_flow(tenant_id, client_id, client_secret)\r\n",
					"    else:\r\n",
					"        print(\"Token is still valid.\")\r\n",
					"        return access_token, expiration_time\r\n",
					"\r\n",
					"def get_workspace_id(access_token, workspace_name):\r\n",
					"    \"\"\"\r\n",
					"    Retrieve the ID of a Power BI workspace based on its display name.\r\n",
					"\r\n",
					"    Args:\r\n",
					"        access_token (str): Access token for Power BI REST API.\r\n",
					"        workspace_name (str): Display name of the Power BI workspace.\r\n",
					"\r\n",
					"    Returns:\r\n",
					"        str: The ID of the specified workspace.\r\n",
					"    \"\"\"\r\n",
					"    try:\r\n",
					"        url = f\"{power_bi_api_url}/groups\"\r\n",
					"        headers = {\"Authorization\": access_token}\r\n",
					"\r\n",
					"        response = requests.get(url, headers=headers)\r\n",
					"        if response.status_code == 200:\r\n",
					"            workspaces = response.json()[\"value\"]\r\n",
					"            for workspace in workspaces:\r\n",
					"                if workspace[\"name\"] == workspace_name:\r\n",
					"                    print(f\"Workspace '{workspace_name}' found with ID: {workspace['id']}\")\r\n",
					"                    return workspace[\"id\"]\r\n",
					"            raise Exception(f\"Workspace '{workspace_name}' not found.\")\r\n",
					"        else:\r\n",
					"            raise Exception(f\"Failed to retrieve workspaces: {response.text}\")\r\n",
					"    except Exception as e:\r\n",
					"        print(f\"Error retrieving workspace ID: {e}\")\r\n",
					"        raise\r\n",
					"\r\n",
					"def get_dataset_id(access_token, workspace_id, dataset_name):\r\n",
					"    \"\"\"\r\n",
					"    Retrieve the ID of a dataset within a Power BI workspace.\r\n",
					"\r\n",
					"    Args:\r\n",
					"        access_token (str): Access token for Power BI REST API.\r\n",
					"        workspace_id (str): ID of the Power BI workspace.\r\n",
					"        dataset_name (str): Name of the dataset.\r\n",
					"\r\n",
					"    Returns:\r\n",
					"        str: The ID of the specified dataset.\r\n",
					"    \"\"\"\r\n",
					"    try:\r\n",
					"        url = f\"{power_bi_api_url}/groups/{workspace_id}/datasets\"\r\n",
					"        headers = {\"Authorization\": access_token}\r\n",
					"\r\n",
					"        response = requests.get(url, headers=headers)\r\n",
					"        if response.status_code == 200:\r\n",
					"            datasets = response.json()[\"value\"]\r\n",
					"            for dataset in datasets:\r\n",
					"                if dataset[\"name\"] == dataset_name:\r\n",
					"                    print(f\"Dataset '{dataset_name}' found with ID: {dataset['id']}\")\r\n",
					"                    return dataset[\"id\"]\r\n",
					"            raise Exception(f\"Dataset '{dataset_name}' not found in workspace '{workspace_id}'.\")\r\n",
					"        else:\r\n",
					"            raise Exception(f\"Failed to retrieve datasets: {response.text}\")\r\n",
					"    except Exception as e:\r\n",
					"        print(f\"Error retrieving dataset ID: {e}\")\r\n",
					"        raise\r\n",
					"\r\n",
					"def refresh_dataset(access_token, workspace_id, dataset_id):\r\n",
					"    \"\"\"\r\n",
					"    Trigger a refresh operation for a Power BI dataset (semantic model).\r\n",
					"\r\n",
					"    Args:\r\n",
					"        access_token (str): Access token for Power BI REST API.\r\n",
					"        workspace_id (str): ID of the Power BI workspace.\r\n",
					"        dataset_id (str): ID of the dataset to refresh.\r\n",
					"\r\n",
					"    Returns:\r\n",
					"        bool: True if the refresh was successfully initiated, False otherwise.\r\n",
					"    \"\"\"\r\n",
					"    try:\r\n",
					"        url = f\"{power_bi_api_url}/groups/{workspace_id}/datasets/{dataset_id}/refreshes\"\r\n",
					"        headers = {\r\n",
					"            \"Authorization\": access_token,\r\n",
					"            \"Content-Type\": \"application/json\"\r\n",
					"        }\r\n",
					"        print(\"Triggering semantic model refresh...\")\r\n",
					"        response = requests.post(url, headers=headers)\r\n",
					"\r\n",
					"        if response.status_code == 202:\r\n",
					"            print(\"Semantic model refresh initiated successfully.\")\r\n",
					"            return True\r\n",
					"        else:\r\n",
					"            print(f\"Failed to initiate refresh. Status Code: {response.status_code}\")\r\n",
					"            print(f\"Response: {response.text}\")\r\n",
					"            return False\r\n",
					"    except Exception as e:\r\n",
					"        print(f\"Error refreshing dataset: {e}\")\r\n",
					"        raise\r\n",
					"\r\n",
					"if __name__ == \"__main__\":\r\n",
					"    try:\r\n",
					"        # Replace these with your Service Principal details and Power BI information\r\n",
					"        print(\"Authenticating to Power BI...\")\r\n",
					"\r\n",
					"        # Step 1: Initial Token Fetch\r\n",
					"        token_details = get_access_token_with_legacy_flow(tenant_id, client_id, client_secret)\r\n",
					"        access_token, token_expiration = token_details\r\n",
					"\r\n",
					"        # Step 2: Retrieve Workspace ID\r\n",
					"        print(f\"Retrieving Workspace ID for '{workspace_display_name}'...\")\r\n",
					"        token_details = get_valid_token(token_details, tenant_id, client_id, client_secret)\r\n",
					"        access_token, _ = token_details  # Ensure valid token\r\n",
					"        workspace_id = get_workspace_id(access_token, workspace_display_name)\r\n",
					"\r\n",
					"        # Step 3: Retrieve Dataset ID\r\n",
					"        print(f\"Retrieving Dataset ID for '{dataset_name}'...\")\r\n",
					"        token_details = get_valid_token(token_details, tenant_id, client_id, client_secret)\r\n",
					"        access_token, _ = token_details  # Ensure valid token\r\n",
					"        dataset_id = get_dataset_id(access_token, workspace_id, dataset_name)\r\n",
					"\r\n",
					"        # Step 4: Trigger Semantic Model Refresh\r\n",
					"        print(\"Initiating semantic model refresh...\")\r\n",
					"        token_details = get_valid_token(token_details, tenant_id, client_id, client_secret)\r\n",
					"        access_token, _ = token_details  # Ensure valid token\r\n",
					"        if refresh_dataset(access_token, workspace_id, dataset_id):\r\n",
					"            print(\"Semantic model refresh initiated successfully.\")\r\n",
					"        else:\r\n",
					"            print(\"Failed to initiate refresh.\")\r\n",
					"\r\n",
					"        # Step 5: Return Results\r\n",
					"        result = {\r\n",
					"            \"workspace_id\": workspace_id,\r\n",
					"            \"dataset_id\": dataset_id,\r\n",
					"            \"access_token\": access_token\r\n",
					"        }\r\n",
					"        print(\"Returning values to the pipeline...\")\r\n",
					"        mssparkutils.notebook.exit(json.dumps(result))\r\n",
					"\r\n",
					"    except Exception as e:\r\n",
					"        print(f\"An error occurred: {e}\")\r\n",
					"        mssparkutils.notebook.exit(json.dumps({\"error\": str(e)}))\r\n",
					"\r\n",
					""
				],
				"execution_count": 5
			}
		]
	}
}